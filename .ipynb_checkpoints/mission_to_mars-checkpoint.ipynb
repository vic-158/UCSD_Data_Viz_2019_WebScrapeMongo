{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Open Instance of Chrome\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs\n",
    "nasa_url = '''https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%\n",
    "2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'''\n",
    "jpl_url = '''https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'''\n",
    "marsweather_url = '''https://twitter.com/marswxreport?lang=en'''\n",
    "marsfacts_url = '''https://space-facts.com/mars/'''\n",
    "hemispheres_url = '''https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Headline and Writeup from NASA Mars Exploration Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with splinter\n",
    "url = nasa_url\n",
    "browser.visit(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve the parent li's for all articles\n",
    "results = soup.find_all('li', class_='slide')\n",
    "\n",
    "#Write News Title and Paragraph\n",
    "news_title = results[0].find('h3').text\n",
    "news_p = results[0].find('div', class_='article_teaser_body').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Featured Image from JPL Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve page with splinter\n",
    "url = jpl_url\n",
    "browser.visit(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Retrieve parent \n",
    "results = soup.find('a', class_='button fancybox')\n",
    "\n",
    "#Write Featured Image URL\n",
    "featured_image_url = f\"https://www.jpl.nasa.gov{results['data-fancybox-href']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve page with splinter\n",
    "url = marsweather_url\n",
    "browser.visit(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "results = soup.find('p', class_='TweetTextSize TweetTextSize--normal js-tweet-text tweet-text')\n",
    "mars_weather = list(results.children)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve page with splinter\n",
    "url = marsfacts_url\n",
    "df = pd.read_html(url)\n",
    "\n",
    "marsfacts = df[0].rename(columns = {0:'Description',1:'Values'})\n",
    "\n",
    "facts_html = marsfacts.to_html()\n",
    "facts_html = facts_html.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = hemispheres_url\n",
    "browser.visit(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all image titles and store in list\n",
    "results = soup.find_all('div', class_='description')\n",
    "title_list = []\n",
    "for result in results:\n",
    "    title_list.append(result.find('h3').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all image URLs\n",
    "list_img_url = []\n",
    "xpath = '//div[@class=\"description\"]/a/h3'\n",
    "clickables = browser.find_by_xpath(xpath)\n",
    "\n",
    "for i in range(len(clickables)):\n",
    "    clickables[i].click()\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    list_img_url.append(list(list(list(soup.find('div',class_='downloads').children)[5].children)[1].children)[0]['href'])\n",
    "    \n",
    "    browser.back()\n",
    "    \n",
    "    clickables = browser.find_by_xpath(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save list of URLs\n",
    "hemisphere_image_urls = []\n",
    "for i in range(len(title_list)):\n",
    "    hemisphere_image_urls.append({\"title\":title_list[i],\"img_url\":list_img_url[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Items into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x119f5f848>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.mars_db\n",
    "collection = db.marsinfo\n",
    "\n",
    "# Dictionary to be inserted into MongoDB\n",
    "post = {\n",
    "    'news_title': news_title,\n",
    "    'news_p': news_p,\n",
    "    'featured_image': featured_image_url,\n",
    "    'mars_weather':mars_weather,\n",
    "    'mars_facts':facts_html,\n",
    "    'hemispheres': hemisphere_image_urls\n",
    "}\n",
    "\n",
    "# Delete all items in collection and Insert dictionary of updated data into MongoDB as a document \n",
    "collection.delete_many({})\n",
    "collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
